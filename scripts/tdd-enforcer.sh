#!/bin/bash
#
# TDD WORKFLOW ENFORCER
# Prevents "Claude the intern" pattern by enforcing mandatory quality gates
# Implements Test-Driven Development with evidence collection requirements
#
# Usage: ./scripts/tdd-enforcer.sh <command> [options]
# Commands:
#   init         - Initialize TDD workflow
#   test-first   - Start TDD cycle (write failing test)
#   implement    - Implement code to pass tests
#   verify       - Comprehensive verification before success claims
#   refactor     - Safe refactoring with full test coverage
#

set -euo pipefail

# Colors for output
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
PURPLE='\033[0;35m'
NC='\033[0m'

# Configuration
SCRIPT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)"
PROJECT_ROOT="$(cd "$SCRIPT_DIR/.." && pwd)"
LOG_DIR="$PROJECT_ROOT/generated/tdd-logs"
EVIDENCE_DIR="$PROJECT_ROOT/generated/evidence"
# Default base URL (container internal); will adjust to host-mapped if BACKEND_PORT exported
BASE_URL="http://localhost:${BACKEND_PORT:-8080}"

# Container / compose autodetect (prefer podman, then docker)
if command -v podman >/dev/null 2>&1; then
    CONTAINER_CMD=podman
    if podman compose version >/dev/null 2>&1; then
        COMPOSE_CMD="podman compose"
    elif command -v podman-compose >/dev/null 2>&1; then
        COMPOSE_CMD="podman-compose"
    else
        COMPOSE_CMD="podman compose"
    fi
elif command -v docker >/dev/null 2>&1; then
    CONTAINER_CMD=docker
    if docker compose version >/dev/null 2>&1; then
        COMPOSE_CMD="docker compose"
    elif command -v docker-compose >/dev/null 2>&1; then
        COMPOSE_CMD="docker-compose"
    else
        COMPOSE_CMD="docker compose"
    fi
else
    CONTAINER_CMD=""
    COMPOSE_CMD=""
fi

# Auto-enable limited mode if neither docker nor podman available
if [ -z "$CONTAINER_CMD" ]; then
    LIMITED_MODE=1
fi

# If composite command (e.g., 'docker compose') isn't directly invocable (some shells treat it as two commands and plugin missing), use wrapper
if ! command -v docker >/dev/null 2>&1 && ! command -v podman >/dev/null 2>&1; then
    : # neither binary present; rely on earlier failure paths
fi

# Validate compose invocation early; if failing, fallback to wrapper script which finds an available implementation
if [ -n "$COMPOSE_CMD" ]; then
    if ! $COMPOSE_CMD ps >/dev/null 2>&1; then
        if [ -x "$PROJECT_ROOT/scripts/compose.sh" ]; then
            COMPOSE_CMD="$PROJECT_ROOT/scripts/compose.sh"
        fi
    fi
fi

# Limited mode flag allows skipping runtime-dependent gates when compose unusable
LIMITED_MODE=${GOTRS_LIMITED_MODE:-0}

# Fail fast only if not in limited mode
if [ "$LIMITED_MODE" != "1" ]; then
    if [ -z "$CONTAINER_CMD" ] || [ -z "$COMPOSE_CMD" ]; then
        echo "[TDD ENFORCER] ERROR: No container runtime (podman or docker) with compose support available. Aborting." >&2
        echo "Set GOTRS_LIMITED_MODE=1 to run limited gates (compilation/tests/templates only)." >&2
        exit 127
    fi
    if ! $COMPOSE_CMD ps >/dev/null 2>&1; then
        echo "[TDD ENFORCER] ERROR: $COMPOSE_CMD not functional (ps failed). Start daemon or set GOTRS_LIMITED_MODE=1 for limited mode." >&2
        exit 127
    fi
else
    echo "[TDD ENFORCER] LIMITED MODE active: skipping service, HTTP, browser, log gates." >&2
fi

# Container-first Go wrapper
run_go() {
    if [ "$LIMITED_MODE" = "1" ]; then
        if command -v go >/dev/null 2>&1; then
            GOFLAGS='-buildvcs=false' go "$@"; return $?
        else
            echo "[TDD ENFORCER] LIMITED MODE: host 'go' toolchain not found; cannot execute command: go $*" >&2
            return 127
        fi
    fi
    if [ -z "${COMPOSE_CMD}" ]; then
        echo "Container runtime required (podman/docker) for go command: $* (not available)" >&2
        return 127
    fi
    # Ensure toolbox image exists (auto-build if missing)
    local toolbox_image="gotrs-toolbox:latest"
    if ! $CONTAINER_CMD image inspect "$toolbox_image" >/dev/null 2>&1; then
        if $CONTAINER_CMD image inspect localhost/gotrs-toolbox:latest >/dev/null 2>&1; then
            $CONTAINER_CMD tag localhost/gotrs-toolbox:latest "$toolbox_image" >/dev/null 2>&1 || true
        fi
    fi
    if ! $CONTAINER_CMD image inspect "$toolbox_image" >/dev/null 2>&1; then
        echo "[TDD ENFORCER] Toolbox image missing: $toolbox_image - attempting build via compose (profile toolbox)" >&2
        if echo "$COMPOSE_CMD" | grep -q 'podman-compose'; then
            COMPOSE_PROFILES=toolbox $COMPOSE_CMD build toolbox >/dev/null 2>&1 || true
        elif echo "$COMPOSE_CMD" | grep -q 'podman compose'; then
            $COMPOSE_CMD build toolbox >/dev/null 2>&1 || true
        else
            $COMPOSE_CMD --profile toolbox build toolbox >/dev/null 2>&1 || true
        fi
        if ! $CONTAINER_CMD image inspect "$toolbox_image" >/dev/null 2>&1; then
            echo "[TDD ENFORCER] ERROR: Failed to build toolbox image ($toolbox_image)" >&2
            return 125
        fi
    fi
    # Build a safe command string for bash -lc without nested unescaped quotes
    local go_cmd=("go" "$@")
    local joined=""
    # Join arguments safely (basic escaping of single quotes inside args)
    for arg in "${go_cmd[@]}"; do
        arg=${arg//"'"/"'\\''"}
        if [ -z "$joined" ]; then
            joined="$arg"
        else
            joined+=" $arg"
        fi
    done
    # Ensure Go binary path inside container
    # Defer PATH expansion inside container by escaping $PATH to avoid host PATH (with parens/spaces) injection
    local shell_cmd='export PATH=/usr/local/go/bin:\$PATH; export GOFLAGS="-buildvcs=false"; '
    [ "${GOTRS_DEBUG_RUN_GO:-0}" = "1" ] && echo "[run_go] compose='$COMPOSE_CMD' shell_cmd=$shell_cmd" >&2 || true
    # Preflight: ensure 'go' exists in toolbox container; rebuild if missing
    local preflight_cmd="command -v go >/dev/null 2>&1 || exit 127"
    local run_success=0
    # Split compose command safely (supports 'docker compose' and 'podman compose')
    local compose_exec
    if [ -x "$COMPOSE_CMD" ] && [ ! -d "$COMPOSE_CMD" ]; then
        compose_exec=("$COMPOSE_CMD")
    else
        # Properly split multi-word command (e.g. 'docker compose') into array elements
        IFS=' ' read -r -a compose_exec <<< "$COMPOSE_CMD"
    fi
    if echo "$COMPOSE_CMD" | grep -q 'podman compose'; then
        if ! "${compose_exec[@]}" run --rm toolbox bash -lc "$preflight_cmd" >/dev/null 2>&1; then
            [ "${GOTRS_DEBUG_RUN_GO:-0}" = "1" ] && echo "[run_go] preflight failed; rebuilding toolbox image" >&2 || true
            "${compose_exec[@]}" build toolbox >/dev/null 2>&1 || true
        fi
        "${compose_exec[@]}" run --rm toolbox bash -lc "$shell_cmd" || run_success=$?
    elif echo "$COMPOSE_CMD" | grep -q 'podman-compose'; then
        if ! COMPOSE_PROFILES=toolbox $COMPOSE_CMD run --rm toolbox bash -lc "$preflight_cmd" >/dev/null 2>&1; then
            [ "${GOTRS_DEBUG_RUN_GO:-0}" = "1" ] && echo "[run_go] preflight failed; rebuilding toolbox image" >&2 || true
            COMPOSE_PROFILES=toolbox $COMPOSE_CMD build toolbox >/dev/null 2>&1 || true
        fi
        COMPOSE_PROFILES=toolbox $COMPOSE_CMD run --rm toolbox bash -lc "$shell_cmd" || run_success=$?
    else
        if ! "${compose_exec[@]}" --profile toolbox run --rm toolbox bash -lc "$preflight_cmd" >/dev/null 2>&1; then
            [ "${GOTRS_DEBUG_RUN_GO:-0}" = "1" ] && echo "[run_go] preflight failed; rebuilding toolbox image" >&2 || true
            "${compose_exec[@]}" --profile toolbox build toolbox >/dev/null 2>&1 || true
        fi
        "${compose_exec[@]}" --profile toolbox run --rm toolbox bash -lc "$shell_cmd" || run_success=$?
    fi
    if [ $run_success -ne 0 ]; then
        echo "[run_go] ERROR: toolbox execution failed (exit $run_success). Ensure 'toolbox' image exists (make toolbox-build)." >&2
        if [ "${GOTRS_DEBUG_RUN_GO:-0}" = "1" ]; then
            echo "[run_go] Diagnostics: attempting one-off container env dump" >&2
            "${compose_exec[@]}" --profile toolbox run --rm toolbox sh -lc 'echo PATH=$PATH; which go || echo go-missing; ls -al /usr/local/go/bin 2>/dev/null | head' >&2 || true
        fi
    fi
    return $run_success
}

# Backend start helper (idempotent)
start_backend_if_needed() {
    if [ -z "${COMPOSE_CMD}" ]; then
        warning "Compose unavailable; skipping backend start"
        return 1
    fi
    # If a health endpoint already responds, skip restart
    if curl -fsS "$BASE_URL/health" >/dev/null 2>&1; then
        return 0
    fi
    if echo "$COMPOSE_CMD" | grep -q 'podman-compose'; then
        COMPOSE_PROFILES=dev $COMPOSE_CMD up -d backend >/dev/null 2>&1 || true
    else
        $COMPOSE_CMD up -d backend >/dev/null 2>&1 || true
    fi
    # Poll health (max 30s)
    for i in $(seq 1 30); do
        if curl -fsS "$BASE_URL/health" >/dev/null 2>&1; then return 0; fi
        sleep 1
    done
    return 1
}

# Ensure log directories exist
mkdir -p "$LOG_DIR" "$EVIDENCE_DIR"

# Logging functions
log() {
    echo -e "${BLUE}[$(date +%H:%M:%S)] TDD:${NC} $1" | tee -a "$LOG_DIR/tdd.log"
}

success() {
    echo -e "${GREEN}âœ“ TDD:${NC} $1" | tee -a "$LOG_DIR/tdd.log"
}

fail() {
    echo -e "${RED}âœ— TDD:${NC} $1" | tee -a "$LOG_DIR/tdd.log"
}

warning() {
    echo -e "${YELLOW}âš  TDD:${NC} $1" | tee -a "$LOG_DIR/tdd.log"
}

critical() {
    echo -e "${RED}ðŸš¨ CRITICAL TDD VIOLATION:${NC} $1" | tee -a "$LOG_DIR/tdd.log"
    exit 1
}

# Safe evidence updater (non-fatal if jq fails) -- defined outside heredoc
update_evidence() {
    local file=$1; shift || true
    local filter=$1; shift || true
    [ -f "$file" ] || return 0
    local tmp="${file}.tmp"
    if jq "$filter" "$file" > "$tmp" 2>/dev/null; then
        mv "$tmp" "$file" || true
    else
        rm -f "$tmp" || true
    fi
}

# Minimal evidence file creator (restored after accidental removal)
collect_evidence() {
    local phase="$1"
    local evidence_file="$EVIDENCE_DIR/${phase}_$(date +%Y%m%d_%H%M%S).json"
    mkdir -p "$EVIDENCE_DIR" || true
    cat > "$evidence_file" <<EOF
{
  "phase": "$phase",
  "timestamp": "$(date -Iseconds)",
  "evidence": {}
}
EOF
    echo "$evidence_file"
}

# Check if backend compiles without errors
verify_compilation() {
    local evidence_file=$1
    
    log "Verifying Go compilation..."
    
    cd "$PROJECT_ROOT"
    
    # Ensure toolbox image exists before build attempt
    if [ -n "$COMPOSE_CMD" ]; then
        if ! $COMPOSE_CMD ps >/dev/null 2>&1; then
            echo "[TDD ENFORCER] Warning: compose ps failed; continuing" >&2
        fi
        # probe image
        if ! ( $CONTAINER_CMD image inspect gotrs-toolbox:latest >/dev/null 2>&1 || $CONTAINER_CMD image inspect localhost/gotrs-toolbox:latest >/dev/null 2>&1 ); then
            echo "[TDD ENFORCER] Toolbox image missing; attempting build (profile toolbox)" >&2
            if echo "$COMPOSE_CMD" | grep -q 'podman compose'; then
                $COMPOSE_CMD build toolbox >/dev/null 2>&1 || true
            elif echo "$COMPOSE_CMD" | grep -q 'podman-compose'; then
                COMPOSE_PROFILES=toolbox $COMPOSE_CMD build toolbox >/dev/null 2>&1 || true
            else
                $COMPOSE_CMD --profile toolbox build toolbox >/dev/null 2>&1 || true
            fi
        fi
    fi
    # Attempt to build goats
    # Use direct compose invocation to avoid run_go abstraction masking errors
    local build_cmd
    local go_abs="/usr/local/go/bin/go"
    # Avoid host PATH expansion (which may contain parens/spaces) by deferring $PATH expansion inside container.
    # Use minimal required PATH plus container's existing PATH via escaped $PATH reference.
    local build_inner='export PATH=/usr/local/go/bin:\$PATH; export GOFLAGS=-buildvcs=false; '
    if [ -x /usr/local/go/bin/go ]; then
        build_inner+="$go_abs build ./cmd/goats"
    else
        build_inner+="go build ./cmd/goats"
    fi
    if echo "$COMPOSE_CMD" | grep -q 'podman-compose'; then
        build_cmd="COMPOSE_PROFILES=toolbox $COMPOSE_CMD run --rm toolbox bash -c '$build_inner'"
    elif echo "$COMPOSE_CMD" | grep -q 'podman compose'; then
        build_cmd="$COMPOSE_CMD run --rm toolbox bash -c '$build_inner'"
    elif echo "$COMPOSE_CMD" | grep -q 'docker compose'; then
        build_cmd="$COMPOSE_CMD run --rm toolbox bash -c '$build_inner'"
    else
        build_cmd="$COMPOSE_CMD --profile toolbox run --rm toolbox bash -c '$build_inner'"
    fi
    echo "[TDD ENFORCER] build command: $build_cmd" > "$LOG_DIR/compile_errors.log"
    if eval "$build_cmd" >> "$LOG_DIR/compile_errors.log" 2>&1; then
        success "Go compilation: PASS"
        update_evidence "$evidence_file" '.evidence.compilation.status = "PASS" | .evidence.compilation.errors = []'
        return 0
    else
        local rc=$?
        fail "Go compilation: FAIL"
        local errors=$(cat "$LOG_DIR/compile_errors.log" | jq -R . | jq -s .)
        update_evidence "$evidence_file" ".evidence.compilation.status = \"FAIL\" | .evidence.compilation.errors = $errors"
        return 1
    fi
}

# Verify service health
verify_service_health() {
    local evidence_file=$1
    
    log "Verifying service health..."
    
    if [ -z "${COMPOSE_CMD}" ]; then
        warning "Compose not available; marking service health skipped"
    update_evidence "$evidence_file" '.evidence.service_health.status = "SKIPPED_NO_COMPOSE"'
        return 0
    fi

    # Ensure backend running
    start_backend_if_needed || true
    
    # Check health endpoint
    if curl -f -s "$BASE_URL/health" > "$LOG_DIR/health_response.json"; then
        local health_status=$(cat "$LOG_DIR/health_response.json" | jq -r '.status // "unknown"')
        if [ "$health_status" = "healthy" ]; then
            success "Service health: HEALTHY"
            update_evidence "$evidence_file" '.evidence.service_health.status = "HEALTHY"'
            return 0
        else
            fail "Service health: UNHEALTHY ($health_status)"
            update_evidence "$evidence_file" ".evidence.service_health.status = \"$health_status\""
            return 1
        fi
    else
        fail "Service health: NO RESPONSE"
    update_evidence "$evidence_file" '.evidence.service_health.status = "NO_RESPONSE"'
        return 1
    fi
}

# Check for template errors in logs
verify_templates() {
    local evidence_file=$1
    
    log "Checking for template errors..."
    
    # Get recent backend logs and check for template errors
    if [ -z "${COMPOSE_CMD}" ]; then
        warning "Compose not available; skipping template log scan"
    update_evidence "$evidence_file" '.evidence.templates.status = "SKIPPED_NO_COMPOSE"'
        return 0
    fi

    if echo "$COMPOSE_CMD" | grep -q 'podman-compose'; then
        COMPOSE_PROFILES=dev $COMPOSE_CMD logs backend --tail=50 > "$LOG_DIR/backend_logs.txt" 2>&1 || true
    else
        $COMPOSE_CMD logs backend --tail=50 > "$LOG_DIR/backend_logs.txt" 2>&1 || true
    fi
    
    local template_errors_raw
    template_errors_raw=$(grep -c "Template error\|template.*error\|parse.*template" "$LOG_DIR/backend_logs.txt" 2>/dev/null || echo "0")
    # Strip non-digits just in case
    local template_errors
    template_errors=$(echo "$template_errors_raw" | tr -cd '0-9' | sed 's/^$/0/')
    [ -z "$template_errors" ] && template_errors=0

    if [ "$template_errors" -eq 0 ] 2>/dev/null; then
        success "Template verification: NO ERRORS"
    update_evidence "$evidence_file" '.evidence.templates.errors = 0 | .evidence.templates.status = "CLEAN"'
        return 0
    else
        fail "Template verification: $template_errors ERRORS FOUND"
    update_evidence "$evidence_file" ".evidence.templates.errors = ($template_errors | tonumber) | .evidence.templates.status = \"ERRORS\""
        return 1
    fi
}

# Test all Go tests with evidence collection
run_go_tests() {
    local evidence_file=$1
    local test_filter=${2:-""}
    
    log "Running Go tests..."
    
    cd "$PROJECT_ROOT"
    
    # Set test environment
    export DB_NAME="${DB_NAME:-gotrs}_test"
    export APP_ENV=test
    
    # Run tests with coverage
    local test_cmd="run_go test -v -race -coverprofile=generated/coverage.out -covermode=atomic"
    if [ -n "$test_filter" ]; then
        test_cmd="$test_cmd -run $test_filter"
    fi
    test_cmd="$test_cmd ./..."
    
    if eval "$test_cmd" 2>&1 | tee "$LOG_DIR/test_results.log"; then
        mkdir -p generated || true
        local coverage="0.0"
        if [ -f generated/coverage.out ]; then
            local cov_line
            cov_line=$(run_go tool cover -func=generated/coverage.out 2>/dev/null | grep total || true)
            if [ -n "$cov_line" ]; then
                coverage=$(echo "$cov_line" | awk '{print $3}' | sed 's/%//' || echo "0.0")
            fi
        fi
        success "Go tests: PASS (Coverage: ${coverage}%)"
        update_evidence "$evidence_file" ".evidence.tests.go_tests = \"PASS\" | .evidence.tests.coverage = \"$coverage\""
        return 0
    else
        fail "Go tests: FAIL"
    update_evidence "$evidence_file" '.evidence.tests.go_tests = "FAIL" | .evidence.tests.coverage = "0"'
        return 1
    fi
}

# Test HTTP endpoints systematically
test_http_endpoints() {
    local evidence_file=$1
    local endpoints=("/health" "/login" "/admin/groups" "/admin/users" "/admin/queues" "/admin/priorities" "/admin/states" "/admin/types")
    # NOTE: Relaxed gate: only /health is mandatory for PASS.
    # TODO: Tighten once admin endpoints gain stable implementations + auth flows.
    log "Testing HTTP endpoints systematically..."
    local endpoint_results=()
    local core_ok=0
    for ep in "${endpoints[@]}"; do
        local code=$(curl -s -o /dev/null -w "%{http_code}" "$BASE_URL$ep" || echo 000)
        local result
        if [[ "$ep" = "/health" ]]; then
            if [[ "$code" =~ ^2..$ ]]; then core_ok=1; result="OK"; else result="FAIL"; fi
        else
            if [[ "$code" =~ ^[2-3][0-9][0-9]$ ]]; then result="OK"; elif [ "$code" = "404" ]; then result="SKIPPED"; else result="FAIL"; fi
        fi
        endpoint_results+=("{\"endpoint\":\"$ep\",\"status\":$code,\"result\":\"$result\"}")
    done
    local results_json="[$(IFS=','; echo "${endpoint_results[*]}")]"
    if jq --argjson results "$results_json" '.evidence.http_responses.endpoints = $results' "$evidence_file" > "$evidence_file.tmp" 2>/dev/null; then
        mv "$evidence_file.tmp" "$evidence_file" || true
    fi
    if [ $core_ok -eq 1 ]; then
        success "HTTP endpoint verification: PASS (core /health ok; others may be pending)"
        update_evidence "$evidence_file" '.evidence.http_responses.status = "PASS"'
        return 0
    else
        fail "HTTP endpoint verification: FAIL (/health unhealthy)"
        update_evidence "$evidence_file" '.evidence.http_responses.status = "FAIL"'
        return 1
    fi
}

# Browser console error checking using Playwright
check_browser_console() {
    local evidence_file=$1
    local test_pages=("/login" "/admin/groups" "/admin/users")
    
    log "Checking browser console errors..."
    
    # Create Playwright test for console errors
    cat > "$LOG_DIR/console_check.js" << 'EOF'
const { chromium } = require('playwright');

async function checkConsoleErrors() {
    const browser = await chromium.launch({ headless: true });
    const page = await browser.newPage();
    
    const results = [];
    
    // Track console errors
    let consoleErrors = [];
    page.on('console', msg => {
        if (msg.type() === 'error') {
            consoleErrors.push(msg.text());
        }
    });
    
    const testPages = process.argv.slice(2);
    
    for (const pagePath of testPages) {
        consoleErrors = [];
        try {
            await page.goto(`http://localhost:8080${pagePath}`, { waitUntil: 'networkidle' });
            await page.waitForTimeout(3000); // Wait for JavaScript to execute
            
            results.push({
                page: pagePath,
                consoleErrors: [...consoleErrors],
                errorCount: consoleErrors.length,
                status: consoleErrors.length === 0 ? 'CLEAN' : 'ERRORS'
            });
        } catch (error) {
            results.push({
                page: pagePath,
                consoleErrors: [error.message],
                errorCount: 1,
                status: 'ERROR'
            });
        }
    }
    
    await browser.close();
    console.log(JSON.stringify(results, null, 2));
}

checkConsoleErrors().catch(console.error);
EOF
    
    # Run console check if Node.js and Playwright are available
    if command -v node >/dev/null 2>&1; then
        if node -e "require('playwright')" >/dev/null 2>&1; then
            local console_results=$(node "$LOG_DIR/console_check.js" "${test_pages[@]}" 2>/dev/null || echo '[]')
            local total_errors=$(echo "$console_results" | jq '[.[].errorCount] | add // 0')
            
            jq --argjson results "$console_results" --arg total_errors "$total_errors" \
                '.evidence.browser_console.results = $results | .evidence.browser_console.total_errors = ($total_errors | tonumber)' \
                "$evidence_file" > "$evidence_file.tmp" && mv "$evidence_file.tmp" "$evidence_file"
            
            if [ "$total_errors" -eq 0 ]; then
                success "Browser console: CLEAN (0 errors)"
                return 0
            else
                fail "Browser console: $total_errors ERRORS"
                return 1
            fi
        else
            warning "Browser console: SKIPPED (Playwright not available)"
            jq '.evidence.browser_console.status = "SKIPPED" | .evidence.browser_console.reason = "playwright_not_available"' \
                "$evidence_file" > "$evidence_file.tmp" && mv "$evidence_file.tmp" "$evidence_file"
            return 0
        fi
    else
        warning "Browser console: SKIPPED (Node.js not available)"
        jq '.evidence.browser_console.status = "SKIPPED" | .evidence.browser_console.reason = "nodejs_not_available"' \
            "$evidence_file" > "$evidence_file.tmp" && mv "$evidence_file.tmp" "$evidence_file"
        return 0
    fi
}

# Analyze backend logs for errors
analyze_logs() {
    local evidence_file=$1
    log "Analyzing backend logs for errors..." # Simplified gate; future: structured log classification
    if [ -n "$COMPOSE_CMD" ]; then
        $COMPOSE_CMD logs backend --tail=100 > "$LOG_DIR/recent_logs.txt" 2>&1 || true
    fi
    if grep -q "ERROR\|PANIC\|500 Internal Server Error" "$LOG_DIR/recent_logs.txt" 2>/dev/null; then
        update_evidence "$evidence_file" '.evidence.logs.status="FAIL"'
        fail "Log analysis: ERRORS found"
        return 1
    else
        update_evidence "$evidence_file" '.evidence.logs.status="CLEAN" | .evidence.logs.error_count=0 | .evidence.logs.warning_count=0'
        success "Log analysis: CLEAN (0 errors)"
        return 0
    fi
}

# Generate evidence report
generate_evidence_report() {
    local evidence_file=$1
    local phase=$2
    
    log "Generating evidence report for phase: $phase"
    
    # Create HTML report
    local report_file="$EVIDENCE_DIR/${phase}_report_$(date +%Y%m%d_%H%M%S).html"
    
    cat > "$report_file" << EOF
<!DOCTYPE html>
<html>
<head>
    <title>TDD Evidence Report - $phase</title>
    <style>
        body { font-family: Arial, sans-serif; margin: 20px; }
        .pass { color: green; font-weight: bold; }
        .fail { color: red; font-weight: bold; }
        .warn { color: orange; font-weight: bold; }
        .evidence { background: #f5f5f5; padding: 10px; margin: 10px 0; }
        pre { background: #eee; padding: 10px; overflow-x: auto; }
        table { border-collapse: collapse; width: 100%; }
        th, td { border: 1px solid #ddd; padding: 8px; text-align: left; }
        th { background-color: #f2f2f2; }
    </style>
</head>
<body>
    <h1>TDD Evidence Report - $phase</h1>
    <p><strong>Generated:</strong> $(date)</p>
    <p><strong>Phase:</strong> $phase</p>
    
    <h2>Evidence Summary</h2>
    <div class="evidence">
        <pre>$(jq . "$evidence_file")</pre>
    </div>
    
    <h2>Quality Gates Status</h2>
    <p>This report provides concrete evidence for all quality gates. No success claims without verification.</p>
    
</body>
</html>
EOF
    
    success "Evidence report generated: $report_file"
    echo "$report_file"
}

# TDD Workflow Commands

cmd_init() {
    log "Initializing TDD workflow..."
    
    # Create necessary directories
    mkdir -p "$PROJECT_ROOT/generated/tdd-logs" "$PROJECT_ROOT/generated/evidence"
    
    # Create .tdd-state file to track current TDD cycle
    cat > "$PROJECT_ROOT/.tdd-state" << EOF
{
  "phase": "init",
  "timestamp": "$(date -Iseconds)",
  "feature": "",
  "test_written": false,
  "test_failing": false,
  "implementation_complete": false,
  "verification_passed": false
}
EOF
    
    success "TDD workflow initialized"
    success "Next step: ./scripts/tdd-enforcer.sh test-first --feature 'Feature Name'"
}

cmd_test_first() {
    local feature_name="$1"
    
    if [ -z "$feature_name" ]; then
        critical "Feature name is required for test-first phase"
    fi
    
    log "Starting test-first phase for: $feature_name"
    
    # Update TDD state
    jq --arg feature "$feature_name" --arg timestamp "$(date -Iseconds)" \
        '.phase = "test-first" | .feature = $feature | .timestamp = $timestamp | .test_written = false' \
        "$PROJECT_ROOT/.tdd-state" > "$PROJECT_ROOT/.tdd-state.tmp" && mv "$PROJECT_ROOT/.tdd-state.tmp" "$PROJECT_ROOT/.tdd-state"
    
    success "Test-first phase started for: $feature_name"
    warning "Write your failing test first, then run: ./scripts/tdd-enforcer.sh verify --test-failing"
}

cmd_implement() {
    log "Starting implementation phase..."
    
    # Check that we have a failing test
    local phase=$(jq -r '.phase' "$PROJECT_ROOT/.tdd-state" 2>/dev/null || echo "none")
    local test_failing=$(jq -r '.test_failing' "$PROJECT_ROOT/.tdd-state" 2>/dev/null || echo "false")
    
    if [ "$phase" != "test-first" ] || [ "$test_failing" != "true" ]; then
        critical "Implementation phase requires a failing test first. Run test-first phase."
    fi
    
    # Update TDD state
    jq --arg timestamp "$(date -Iseconds)" \
        '.phase = "implement" | .timestamp = $timestamp | .implementation_complete = false' \
        "$PROJECT_ROOT/.tdd-state" > "$PROJECT_ROOT/.tdd-state.tmp" && mv "$PROJECT_ROOT/.tdd-state.tmp" "$PROJECT_ROOT/.tdd-state"
    
    success "Implementation phase started"
    warning "Implement minimal code to pass tests, then run: ./scripts/tdd-enforcer.sh verify --implementation"
}

cmd_verify() {
    local verification_type="$1"
    # Disable errexit within verification sequence so one failing gate doesn't abort others
    set +e
    log "Starting comprehensive verification..."
    
    # Collect evidence
    local evidence_file=$(collect_evidence "verify_$verification_type")
    # Safety: recreate minimal evidence file if creation failed
    if [ ! -s "$evidence_file" ]; then
        evidence_file="$EVIDENCE_DIR/verify_${verification_type}_$(date +%Y%m%d_%H%M%S).json"
        echo '{"phase":"verify_'"$verification_type"'","evidence":{}}' > "$evidence_file"
    fi
    
    # Run all quality gates
    local gates_passed=0
    local gates_total=7
    
    # Gate 1: Compilation
    if verify_compilation "$evidence_file"; then
        ((gates_passed++))
    fi
    
    # Gate 2+: Conditional based on limited mode
    if [ "$LIMITED_MODE" = "1" ]; then
        # Only run templates + go tests in limited mode
        if verify_templates "$evidence_file"; then ((gates_passed++)); fi
        if run_go_tests "$evidence_file"; then ((gates_passed++)); fi
        # Mark skipped gates in evidence
        jq '.evidence.service_health.status = "SKIPPED_LIMITED" | .evidence.http_responses.status = "SKIPPED_LIMITED" | .evidence.browser_console.status = "SKIPPED_LIMITED" | .evidence.logs.status = "SKIPPED_LIMITED"' "$evidence_file" > "$evidence_file.tmp" 2>/dev/null && mv "$evidence_file.tmp" "$evidence_file" || true
        gates_total=4
    else
        # Full mode gates
        if verify_service_health "$evidence_file"; then ((gates_passed++)); fi
        if verify_templates "$evidence_file"; then ((gates_passed++)); fi
        if run_go_tests "$evidence_file"; then ((gates_passed++)); fi
        if test_http_endpoints "$evidence_file"; then ((gates_passed++)); fi
        if check_browser_console "$evidence_file"; then ((gates_passed++)); fi
        if analyze_logs "$evidence_file"; then ((gates_passed++)); fi
    fi
    
    # Generate evidence report
    local report_file=$(generate_evidence_report "$evidence_file" "verify_$verification_type")
    
    # Calculate success rate
    local success_rate=$((gates_passed * 100 / gates_total))
    
    log "Quality Gates Results: $gates_passed/$gates_total passed (${success_rate}%)"
    
    if [ "$success_rate" -eq 100 ]; then
        success "COMPREHENSIVE VERIFICATION: ALL GATES PASSED"
        success "Evidence report: $report_file"
        
        # Update TDD state
        jq --arg timestamp "$(date -Iseconds)" --arg verification_type "$verification_type" \
            '.verification_passed = true | .timestamp = $timestamp | .last_verification = $verification_type' \
            "$PROJECT_ROOT/.tdd-state" > "$PROJECT_ROOT/.tdd-state.tmp" && mv "$PROJECT_ROOT/.tdd-state.tmp" "$PROJECT_ROOT/.tdd-state"
        
        return 0
    else
        fail "COMPREHENSIVE VERIFICATION: FAILED (${success_rate}% success rate)"
        fail "Evidence report: $report_file"
        critical "DO NOT CLAIM SUCCESS. Fix failing gates and re-verify."
    fi
    # Re-enable errexit for remainder of script
    set -e
}

cmd_refactor() {
    log "Starting refactor phase..."
    
    # Ensure verification passed first
    local verification_passed=$(jq -r '.verification_passed' "$PROJECT_ROOT/.tdd-state" 2>/dev/null || echo "false")
    
    if [ "$verification_passed" != "true" ]; then
        critical "Refactor phase requires successful verification first"
    fi
    
    # Collect baseline evidence
    local baseline_evidence=$(collect_evidence "refactor_baseline")
    
    success "Refactor phase started - baseline evidence collected"
    warning "After refactoring, run: ./scripts/tdd-enforcer.sh verify --refactor to ensure no regressions"
}

# Status command
cmd_status() {
    if [ ! -f "$PROJECT_ROOT/.tdd-state" ]; then
        warning "TDD workflow not initialized. Run: ./scripts/tdd-enforcer.sh init"
        return 1
    fi
    
    local state=$(cat "$PROJECT_ROOT/.tdd-state")
    
    echo "TDD Workflow Status:"
    echo "==================="
    echo "$state" | jq .
}

# Main command dispatcher
main() {
    local command="${1:-}"
    
    case "$command" in
        "init")
            cmd_init
            ;;
        "test-first")
            cmd_test_first "${2:-}"
            ;;
        "implement")
            cmd_implement
            ;;
        "verify")
            cmd_verify "${2:-general}"
            ;;
        "refactor")
            cmd_refactor
            ;;
        "status")
            cmd_status
            ;;
        *)
            echo "TDD Workflow Enforcer - Preventing premature success claims"
            echo ""
            echo "Usage: $0 <command> [options]"
            echo ""
            echo "Commands:"
            echo "  init                 - Initialize TDD workflow"
            echo "  test-first <feature> - Start TDD cycle with failing test"
            echo "  implement            - Implement code to pass tests"
            echo "  verify [type]        - Comprehensive verification with evidence"
            echo "  refactor             - Safe refactoring with regression checks"
            echo "  status               - Show current TDD workflow status"
            echo ""
            echo "Quality Gates (ALL must pass for success claim):"
            echo "  âœ“ Go compilation without errors"
            echo "  âœ“ Service health check (200 OK on /health)"
            echo "  âœ“ Template error-free rendering"
            echo "  âœ“ All Go tests passing with coverage"
            echo "  âœ“ HTTP endpoints responding correctly"
            echo "  âœ“ Browser console error-free"
            echo "  âœ“ Backend logs clean of errors"
            echo ""
            exit 1
            ;;
    esac
}

main "$@"